---
title: '集群系统建模综述'
date: 2019-12-07
permalink: /posts/2019/12/Intelligent_control_model/
tags:
  - Intelligent control
  - model
---

集群系统模型一般包含两部分：拓扑模型和节点动力学模型。拓扑模型决定了智能体间的连接关系，通常用图表示，如：无向图、有向图、加权图等。节点动力学模型用于描述每个智能体自身的运动规则，通常采用一阶、二阶积分器模型、一般系统模型等方法。

最早的集群系统模型是由Reynolds[1]于1987年提出的Boids模型，该模型用计算机来模拟群体行为，并给出了智能集群系统满足的三个规则：

1）速度匹配：agent尽量与邻居agents速度和方向的平均值保持一致；

2）聚集：agent尽量向邻居agents的平均位置运动；

3）避免碰撞：相邻agents之间避免发生碰撞。

2001年，Reynolds将Boids模型所有资料公布于网站上，包括程序、示例、相关论文等。在Boids模型的基础上，1995年Vicsek等人[2]将其简化，提出了一种离散多智能体模型----Vicsek模型用于模拟大量粒子涌现出一致性的现象，其实质是Boids模型中速度匹配的动力学实现。Vicsek模型刻画了多个粒子构成的自治系统的同步运动．在这个模型中粒子遵循如下规则：

1）系统中运动的粒子具有常速率  ；

2）粒子存在一个影响半径  ，即系统中的任意一对粒子，只有这对粒子之间的直线距离小于  时，他们才存在相互的影响；

3）粒子每一时刻的运动方向跟上一时刻它的影响半径范围内的其他所有粒子的平均运动方向相同。

同时Vicsek模型引入了数学化描述，如公式所示：

$${\rm{x}_i}(t + 1) = {{\rm{x}}_i}(t) + {{\rm{v}}_i}(t)\Delta t\\
{\theta _i}(t + 1) = <{\theta _i}(t){>_r} + {\Delta _i}(t)$$

其中:  ${{\rm{x}}_i}(t)$为 agent i在t时刻的位置，${v_i}(t)$为agent i在t时刻的速度，${\theta _i}(t)$为agent i 在t时刻的航向，$<{\theta _i}(t){ > _r}$为agent i及其周围agents的航向的平均，${\Delta _i}(t)$为扰动项。利用$\varphi$评判是否同步的标注，如公式：

$$\varphi  = \frac{1}{{N{v_0}}}\left| {\sum\limits_{i = 1}^N {{{\rm{v}}_i}} } \right|$$

 $\varphi$可以描述为归一化的平均速度，当速度一致时， $\varphi =1 $。完全杂乱无章时，$\varphi=0$。在[2]中也给出了结果。

2003年，Jadbabaie等人[3]在无噪声的假设条件下对Vicsek模型进行了简化，用矩阵论和图论（无向图）给出了Vicsek模型的收敛性的理论证明，指出：只要满足联通，粒子的运动方向就能达到一致。与Vicsek描述类似，Jadbabaie引入了图论，将无领导的模型描述为：
$${\theta _i}(t + 1) = \frac{1}{{1 + {k_i}(t)}}({\theta _i}(t) + \sum\limits_{j \in {N_i}(t)} {{\theta _j}(t)} )$$

其中${k_i}(t)$为agent i周围的agents数目，\sum\limits_{j \in {N_i}(t)} {{\theta _j}(t)}描述为周围agents航向之和，{N_i}(t) 表示t时刻agent i的拓扑连接矩阵。如果agents间距离较远，系统容易发生聚堆、簇分离的情况，因此Jadbabaie等人又引入了虚拟领航员，作为导航项  ，将公式(3)进行修改，得到如公式(4)的系统模型：

{\theta _i}(t + 1) = \frac{1}{{1 + {k_i}(t) + {b_i}(t)}}({\theta _i}(t) + \sum\limits_{j \in {N_i}(t)} {{\theta _j}(t)}  + {b_i}(t){\theta _0})

当需要领航员的情况下，{b_i}(t)=1，否则{b_i}(t)=0。集群系统模型自此从群体动力学模型时代进入了网络化系统与图论描述时代。

Olfati-Saber等人[4]–[7]在Jadbabaie工作的基础上研究了系统的网络拓扑结构与系统收敛性之间的关系，他指出如果系统的网络拓扑结构是强连通的有向图，则对于任意初始状态，系统的状态是渐近收敛的，且对于强连通有效拓扑结构下的多智能体系统，平均一致收敛的充要条件是它的信息交换图是平衡图。

Olfati-Saber将系统描述为G = ({\cal V},{\cal E},{\cal A})，其中 {\cal V}节点，{\cal E} 为边，{\cal A}为邻接矩阵，它的元素均为非负。agent邻居的集合为：

{N_J}: = \bigcup\limits_{{v_i} \in J} {{N_i}}  = \left\{ {{v_j} \in {\cal V}:{v_i} \in J,\left( {{v_i},{v_j}} \right) \in {\cal E}} \right\},J \subseteq {\cal V}

动力学模型建立为： {\dot x_i} = f\left( {{x_i},{u_i}} \right),\quad i \in {\cal I} 

定义有向拉普拉斯矩阵为：{\cal L}({\cal G}) = L = \Delta  - {\cal A}，其中 \Delta  为入度矩阵。

对于切换拓扑的模型定义为：
$$
\begin{array}{l}
{\Gamma _n} = \left\{ {G = ({\cal V},{\cal E},{\cal A}):{\mathop{\rm rank}\nolimits} ({\cal L}(G)) = n - 1,{{\bf{1}}^T}{\cal L}(G) = {\bf{0}}} \right\}\\
\dot x(t) =  - {\cal L}\left( {{G_k}} \right)x(t)\quad k = s(t),{G_k} \in {\Gamma _n}
\end{array}
$$

第一个式子是对强连通网络的描述，第二个式子是对系统的描述。其中s(t):{_{ \ge 0}} \to {{\cal I}_{{\Gamma _n}}}是切换信号。

具有时延的agent i模型为:

$${\dot x_i}(t) = \sum\limits_{{v_j} \in {N_i}} {{a_{ij}}} \left[ {{x_j}\left( {t - {\tau _{ij}}} \right) - {x_i}\left( {t - {\tau _{ij}}} \right)} \right]$$

其中，    是agent i与agent j之间的时延。整个系统模型的传递函数为：

G(s) = {(sI + L(s))^{ - 1}}

其中 L(s) = {e^{ - \tau s}}L(G)

在Olfati-Saber的基础上，美国加州大学河滨分校任伟教授等人[8]固定拓扑结构的假设下，将强连通拓扑条件弱化为只要在一段时间内网络拓扑子图的联合图包含一条有向生成树，则系统可实现一致性；在动态变化的交互拓扑下，如果有向交互图的并集在系统演化过程中有足够频繁的生成树，则也可以实现信息渐近一致。其离散系统建模与连续系统建模为：

\xi [k + 1] = D[k]\xi [k]

\dot \xi (t) = C(t)\xi (t)

其中\xi  = {\left[ {\begin{array}{*{20}{c}}
{{\xi _1},}&{ \cdots ,}&{{\xi _n}}
\end{array}} \right]^T},D = \left[ {{d_{ij}}} \right],{d_{ij}} = {\alpha _{ij}}[k]{G_{ij}}[k]/\sum\nolimits_{j = 1}^n {{\alpha _{ij}}[k]{G_{ij}}[k]}， {\alpha _{ij}}[k]权重，在i和j有信息交互时：

{G_{ij}}[k] = 1;C = \left[ {{c_{ij}}} \right],(i,j) \in {\cal I}{c_{ii}} =  - \sum\limits_{j \ne i} {\left( {{\sigma _{ij}}(t){G_{ij}}(t)} \right)};{c_{ij}} = {\sigma _{ij}}(t){G_{ij}}(t),j \ne i

除此之外，Cucker和Smale[9]在Vicsek和Jadbabaie工作的基础上提出了一个非常有意义的集群模型(CS模型)，在模型中所有agent具有惯性，且整个系统完全驱动．在CS模型中，每个agent会对其速度进行自我调节，即通过自己在时刻t的速度跟其他agent在时刻t的速度差的加权平均值来调节自己下一时刻的速度．区别于之前的模型需要在无限时间序列上的一个假设，CS模型的收敛结果只依赖于初始状态条件和影响参数．在CS模型中，也做了一些理想化处理：

１）．所有agent之间都有相互影响；

２）．agent受其它agent影响的强弱跟它们之间绝对距离和速度差有关．

连续CS模型：考虑一个具N个agent的多智能复杂系统，对于agent i，它在t时刻的位移记为{{\rm{x}}_i}(t)，速度记为{{\rm{v}}_i}(t)，则{\rm{(}}{{\rm{x}}_i}(t),{{\rm{v}}_i}(t))满足：

\begin{array}{l}
\dfrac{{{\rm{d}}{{\bf{x}}_i}(t)}}{{{\rm{d}}t}} = {{\bf{v}}_i}(t)\\
\dfrac{{{\rm{d}}{{\bf{v}}_i}(t)}}{{{\rm{d}}t}} = \alpha \sum\limits_{j \in {N_j} \ne i} {{a_{ij}}} \left( {\left\| {{{\bf{x}}_j}(t) - {{\bf{x}}_i}(t)} \right\|} \right)\left( {{{\bf{v}}_j}(t) - {{\bf{v}}_i}(t)} \right)
\end{array}

这里  {a_{ij}}(t) = \frac{1}{N}\phi \left( {\left\| {{{\bf{x}}_j}(t) - {{\bf{x}}_i}(t)} \right\|} \right),\phi (r) = \frac{1}{{{{\left( {1 + |{\bf{r}}{|^2}} \right)}^\beta }}},\alpha ,\beta  > 0

2011年美国马里兰大学终身杰出教授Tadmor等人[10]改进了CS模型，在CS模型基础上建立一个新的多智能复杂系统的集群模型(MT)。在这个模型中不仅考虑了agent的数量还考虑了agent在空间中的几何关系．由于相对距离的引进使原CS模型中的对称性质遭到破坏，Tadmor通过引进一个全新的分析方法对复杂系统的集群性质进行了开创性的研究．

连续MT模型：考虑一个具N个agent的复杂系统，对于agent i，它在t时刻的位移记为{{\rm{x}}_i}(t)，速度记为{{\rm{v}}_i}(t)，则{\rm{(}}{{\rm{x}}_i}(t),{{\rm{v}}_i}(t))满足：

\begin{array}{l}
\dfrac{{{\rm{d}}{{\bf{x}}_i}(t)}}{{{\rm{d}}t}} = {{\bf{v}}_i}(t)\\
\dfrac{{{\rm{d}}{{\bf{v}}_i}(t)}}{{{\rm{d}}t}} = \alpha \sum\limits_{j \in {N_j} \ne i} {{b_{ij}}} \left( {\left\| {{{\bf{x}}_j}(t) - {{\bf{x}}_i}(t)} \right\|} \right)\left( {{{\bf{v}}_j}(t) - {{\bf{v}}_i}(t)} \right)
\end{array}

其中  {b_{ij}}(t) = \frac{{\phi \left( {\left\| {{{\bf{x}}_j}(t) - {{\bf{x}}_i}(t)} \right\|} \right)}}{{\sum\limits_{k \in } \phi  \left( {\left\| {{{\bf{x}}_k}(t) - {{\bf{x}}_i}(t)} \right\|} \right)}},\phi (r) = \frac{1}{{{{\left( {1 + |{\bf{r}}{|^2}} \right)}^\beta }}},\alpha ,\beta  > 0

在CS模型中agent之间的影响机制为基础，美国的Shen教授[11]提出了一个特殊的具领导机制和分等级机制的集群模型(HL)。HL模型中每个成员都属于和它对应的一个等级，对它们从高到低依次排序．成员们遵循这样一个影响机制一低等级的成员只能够被高等级的成员影响和领导。

HL模型：考虑由作(k+1)个agent 组成的具等级制度的复杂系统，对agent 进行标记 \left[ {\begin{array}{*{20}{c}}
0&1& \cdots &k
\end{array}} \right]每个等级对应相应的agent ，满足：

1) 当j < i时，{a_{ij}}(t) \ne 0；

2) 若agent i的领导组成的集合是L = \left\{ {{a_{ij}}(t) > 0} \right\}，那么对于任意的i > 0我们都有 L \ne \emptyset 

  表示agent i被agent j领导．这样的模型称为HL模型。

哈工大Li等人[12]在Shen的基础上改进了HL模型，建立了一个更为一般的单领导机制的多智能复杂系统集群模型(RL)。在这个模型中存在一个全局领导者，它不受其它agent 的影响，但是直接或者间接地影响着其它所有agent ．这个模型更好地揭示了全体的合作信息交换的优点

2013年哈工大Dong等人[13]在Shen的基础上研究了具自由意志的离散HL模型，给出了一个自由意志函数控制的条件以确保系统的集群性．在上述基础上，2016年湖南大学李乐博士在其博士论文中提出了HR模型，考虑一个有N个agent 的自适应复杂系统．假设系统中存在K个等级(整数K＞1)。等级ｉ记为“ {R_i} ”，并且这个等级存在{N_i}个agent。对于等级{R_i}中的agent i，它在t时刻的位移记为{{\rm{x}}_i}(t)，速度记为{{\rm{v}}_i}(t)，则{\rm{(}}{{\rm{x}}_i}(t),{{\rm{v}}_i}(t))满足:

\begin{array}{l}
\dfrac{{{\rm{d}}{{\bf{x}}_i}(t)}}{{{\rm{d}}t}} = {{\bf{v}}_i}(t)\\
\dfrac{{{\rm{d}}{{\bf{v}}_i}(t)}}{{{\rm{d}}t}} = \alpha \sum\limits_{j \in {{\bf{R}}_{i - 1}} + {_i},j \ne i} {{b_{ij}}} \left( {\left\| {{{\bf{x}}_j}(t) - {{\bf{x}}_i}(t)} \right\|} \right)\left( {{{\bf{v}}_j}(t) - {{\bf{v}}_i}(t)} \right),i \notin {_1}
\end{array}

[14]–[16]提出了一种经典的非线性动力学模型：Kuramoto模型，该模型由n个耦合振荡器组成，其动力学方程[16]为：

\begin{array}{l}
\dot \theta  = \omega  - \frac{K}{N}B\sin ({B^T}\theta )\\
{r^2} = \frac{{{N^2} - 2e + 2{\bf{1}}_e^T\cos \left( {{B^T}\theta } \right)}}{{{N^2}}}
\end{array}

其中  为具有N个节点、e个边的有向图的incidence矩阵，j传输到i的时候{B_{ij}} = 1，反之{B_{ij}} = -1，其他情况时{B_{ij}} = 0,\theta ,\omega分别表示振荡器的相位和固有频率，K表示耦合的强度。

考虑时延的模型[15]为：

{\dot \theta _i} = {\omega _i} + \frac{K}{{{n_i}}}\sum\limits_{j = 1}^N {{A_{ij}}} \sin \left( {{\theta _j}\left( {t - {\tau _{ij}}} \right) - {\theta _i}(t)} \right)

文献[17]中构建多智能体系统的领导编队的线性多智能体系统如下所示：

\begin{array}
\dot{v} &=E v+H w \\ 
\dot{x}_{i} &=A_{i} x_{i}+B_{i} u_{i}+D_{i} v \\ 
e_{i} &=C_{i} x_{i}+F_{i} v, \quad i=1,2 \ldots, N 
\end{array}

其中{x_i} \in {\mathbb{R}^{{n_i}}},{u_i} \in \mathbb{R},{e_i} \in \mathbb{R}是follower i的状态、控制信号、跟随误差；v \in \mathbb{R}^q是leader的状态，由第一个式子构建。{D_i}v是扰动项， - {F_i}v为参考项。

Brunovsky型是一种具有代表性的标准高阶非线性集群系统[9]，这类的agent模型通过一个高阶积分器耦合未知非线性动力学以及未知扰动来表示:

\begin{array}{l}
{{\dot x}_{ij}} = {x_{i + 1,j}}\\
{{\dot x}_{nj}} = {f_j}({x_j}) + {u_j} + {\zeta _j}
\end{array}

其中i=1，…，n，{x_{ij}} \in {\bf{R}}是智能体j的第i阶状态；{x_j} = {\left[ {\begin{array}{*{20}{c}}
{{x_{1j}}}& \cdots &{{x_{nj}}}
\end{array}} \right]^T}是智能体j的状态向量；未知函数{f_j}(\cdot):{R^n} \to R在R^n上局部Lipschitz，且{f_j}(0) = 0，{\zeta _j} \in R是未知的但是有界的外部扰动。

文献[18]中考虑N个跟随者，M个领航者（与其他agent不连接）的情况，系统的Laplacian矩阵  写为:

L = \left[ {\begin{array}{*{20}{c}}
{{0_{m \times m}}}&{{0_{m \times n}}}\\
{{L_{n \times m}}}&{{L_{n \times n}}}
\end{array}} \right]

考虑时延的跟随者的状态方程可以写为：

{\dot X_F}(t) =  - ({L_{n \times n}} \otimes {I_p}){X_F}(t - \tau ) - ({L_{n \times m}} \otimes {I_p}){X_L}(t - \tau )

其中p为状态量x的维数。

清华大学王龙等人[19]在2011年提出异质集群系统模型，将一阶、二阶模型混合，建立系统模型，如下：

\left\{ {\begin{array}{*{20}{l}}
{{{\dot x}_i}(t) = {v_i}(t),}&{i \in {{\cal I}_m}}\\
{{{\dot v}_i}(t) = {u_i}(t),}&{i \in {{\cal I}_m}}\\
{{{\dot x}_i}(t) = {u_i}(t),}&{i \in \{ m + 1, \ldots ,n\} }
\end{array}} \right.

 {x_i} \in \mathbb{R},{v_i} \in \mathbb{R},{u_i} \in\mathbb{R} 是agent i的位置、速度、控制信号。

在[19]基础上，Kim等人[20]则在考录环境因素影响时，agent之间的通信连接可能中断或重连的情况，他们把这种情况描述为一个伯努利概率序列的数学模型，根据通信中断前的一步信息来设计控制协议，然后利用线性矩阵不等式工具，解决了一阶、二阶异质集群系统在离散时间情况下的俊芳一致性控制问题。

Liu则在王龙等人[19]基础上，将异质系统扩展到更为复杂的情况：即异质系统由线性一阶、线性二阶、非线性Eulre-Lagrange三类智能体组成，并在非线性agent的参数已知和非已知的情况下解决了异质多agent的编队和聚集问题。

\begin{array}{*{20}{l}}
{{{\dot x}_i}(t) = {v_i}(t),}&{i \in {{\cal I}_l}}\\
{{{\dot v}_i}(t) = {u_i}(t),}&{i \in {{\cal I}_l}}\\
\begin{array}{l}
{{\dot x}_i}(t) = {u_i}(t),\\
{{\dot x}_i}(t) = {v_i}(t),\\
{M_i}({x_i}){{\dot v}_i} + {C_i}({x_i},{v_i}){v_i} = {u_i}(t),
\end{array}&\begin{array}{l}
i \in \{ l + 1, \ldots ,m\} \\
i \in \{ m + 1,...,n\} \\
i \in \{ m + 1,...,n\} 
\end{array}
\end{array}

 {x_i} \in \mathbb{R},{v_i} \in \mathbb{R},{u_i} \in\mathbb{R} 是agent i的位置、速度、控制信号， {M_i}({x_i}) \in R为一般惯性矩阵，{C_i}({x_i},{\dot x_i}) \in R为科氏力和离心力矩阵，E-L方程需满足以下4条假设条件：

\begin{array}{l}
0 < {\lambda _m}\left\{ {{M_i}\left( {{x_i}} \right)} \right\}I \le {M_i}\left( {{x_i}} \right) \le {\lambda _M}\left\{ {{M_i}\left( {{x_i}} \right)} \right\}I < \infty \\
{M_i}\left( {{x_i}} \right){{\ddot x}_i} + {C_i}\left( {{x_i},{{\dot x}_i}} \right){{\dot x}_i} = {Y_i}\left( {{x_i},{{\dot x}_i},{{\ddot x}_i}} \right){\theta _i}\\
{r^T}\left( {{{\dot M}_i}\left( {{x_i}} \right) - 2{C_i}\left( {{x_i},{{\dot x}_i}} \right)} \right)r = 0\\
\left\| {{C_i}\left( {{x_i},{{\dot x}_i}} \right)} \right\| \le {k_C}\left\| {{{\dot x}_i}} \right\|
\end{array}

事件驱动建模与上述情况相似，不再赘述。事件驱动集群系统控制典型文献[21], [22]。



在强化学习领域，建模主要围绕MDP和博弈论进行：

马尔可夫决策过程(MDP)可以由一个元组 (S,A,c,P,\rho )来表示，其中

S ：表示状态空间；

 A：动作空间；

c(a,s)\in[0,\infty]：代价函数；

  P(s'|s,a)：状态转移概率；

 \rho(s) ：初始状态概率分布。

部分可观的马尔可夫决策过程(POMDP)是MDP 的更一般性描述。一般来说，POMDP中智能体 i 可以描述为POMD{P_i} =  < S,{A_i},{T_i},{\mathbb{O}_i},{O_i},{R_i} > ，其中：

S ：环境的有限状态集；

A_i ：智能体 i 的行为集；

 T_i：智能体 i 在一种状态下采取行为a，到达某一状态的概率的集合；

 {\mathbb{O}_i}：智能体 i 的观测(observation)；

{O_i}：智能体 i 的观测函数(observation function):定义了给定动作的观察概率；

{R_i}：智能体 i 的奖励函数，代表i的偏好。

由于代理是针对越来越复杂的环境构建的，一组决策者需要以分散的方式做出选择时，可以将问题建模为分散的部分可观察的马尔可夫决策过程 (Decentralized POMDP) [23]。虽然Dec-POMDP模型为不确定性下的协同顺序决策提供了一个丰富的框架，但该模型的计算复杂度是一个重要的研究挑战。它是部分可观测马尔可夫决策过程(POMDP)框架的扩展。一般来说，Dec-POMDP中智能体i可以描述为 POMD{P_i} =  < I,S,{A_i},{T_i},{R_i},{\mathbb{O}_i},{O_i},h > ，其中：

I：n个agents的集合

S ：环境的有限状态集；

A_i：智能体 i 的行为集，结连行为的集合：A = { \times _i}{A_i}；

T_i：agent i在一种状态下采取行为a，到达某一状态的概率的集合；

{\mathbb{O}_i}：agent i的观测(observation)，结连观测的集合 :\mathbb{O}=\times_i{\mathbb{O}_i} 

O_i：智能体 i 的观测函数(observation function):定义了给定动作的观察概率；

R_i：智能体 i 的奖励函数，代表i的偏好，R(s, a)表示状态s下采取动作a的立即回报。

h：问题的维度，始终为一个正整数

Multi-agent Markov decision process(MMDP)[23]:相较于Dec-POMDP，多智能体MDP的描述与之相似，即为：MMD{P_i} =  < I,S,{A_i},{T_i},{R_i},h > 。

与博弈论结合，Hu 等人[24]提出了Stochastic game模型:

I = \left\{ {{\rm{1}} \cdots ,n} \right\}  ：n个agents的集合

S：环境的有限状态集；

对于每个agent i，有限行为集{A_i}，回报函数S \times A \to {R_i}，其中A = {A_1} \times {A_2} \times  \cdots  \times {A_n}

  {T_i}：agent i在某状态下采取行为a，到达另一状态的概率 S \times A \times S \to \left[ {\begin{array}{*{20}{c}}
0&1
\end{array}} \right]

与上述的模型不同，一般随机博弈为了寻找一个Nash均衡点，其满足对于所有的{\pi ^i} \in {\Pi ^i}：

{v^i}\left( {s,\pi _*^1, \ldots ,\pi _*^n} \right) \ge {v^i}\left( {s,\pi _*^1, \ldots ,\pi _*^{i - 1},{\pi ^i},\pi _*^{i + 1}, \ldots ,\pi _*^n} \right)

与图论结合Zhang等人[25]提出了Networked Multi-Agent MDP模型，其同样可以描述为一个元组:

\left( {{\cal S},{{\left\{ {{{\cal A}^i}} \right\}}_{i \in {\cal N}}},P,{{\left\{ {{R^i}} \right\}}_{i \in {\cal N}}},{{\left\{ {{{\cal G}_t}} \right\}}_{t \ge 0}}} \right)

其中：{\left\{ {{{\cal G}_t} = \left( {{\cal N},{{\cal E}_t}} \right)} \right\}_{t \ge 0}}是一个带有时延的N个agent的通信网络，S为全局状态空间，{\cal A} = \prod\nolimits_{i = 1}^N {{{\cal A}^i}}为所有agent的结连行为空间，{R^i}:{\cal S} \times {\cal A} \to R为局部回报函数，P:{\cal S} \times {\cal A} \times {\cal S} \to [0,1]表示状态转移概率。Zhang等人在文中假设状态和结连行为空间全局可观，回报函数仅局部可观。

参考文献

[1]   R. C.W, “Flocks, Herds, and Schools: A Distributed Behavioral Model,” Tech. Coloproctol., vol. 21, no. 2, pp. 25–34, 1987.

[2]   T. Vicsek, A. Czirk, E. Ben-Jacob, I. Cohen, and O. Shochet, “Novel type of phase transition in a system of self-driven particles,” Phys. Rev. Lett., vol. 75, no. 6, pp. 1226–1229, 1995.

[3]   A. Jadbabaie, J. Lin, and A. S. Morse, “Coordination of Groups of Mobile Autonomous Agents Using Nearest Neighbor Rules,” IEEE Trans. Automat. Contr., vol. 48, no. 6, pp. 988–1001, 2003.

[4]   R. Olfati-Saber, J. A. Fax, and R. M. Murray, “Consensus and Cooperation in Networked Multi-AgentSystems,” Proc. IEEE, vol. 95, no. 1, pp. 215–233, 2007.

[5]   R. Olfati-Saber, “Flocking for multi-agent dynamic systems: Algorithms and theory,” IEEE Trans. Automat. Contr., vol. 51, no. 3, pp. 401–420, 2006.

[6]   L. Moreau, “Stability ofMultiagent SystemsWith Time-Dependent Communication Links,” IEEE Trans. Automat. Contr., vol. 50, no. 2, pp. 169–182, 2005.

[7]   R. Olfati-Saber and R. M. Murray, “Consensus problems in networks of agents with switching topology and time-delays,” IEEE Trans. Automat. Contr., vol. 49, no. 9, pp. 1520–1533, 2004.

[8]   W. Ren and R. W. Beard, “Consensus seeking in multiagent systems under dynamically changing interaction topologies,” IEEE Trans. Automat. Contr., vol. 50, no. 5, pp. 655–661, 2005.

[9]   H. Zhang and F. L. Lewis, “Adaptive cooperative tracking control of higher-order nonlinear systems with unknown dynamics,” Automatica, vol. 48, no. 7, pp. 1432–1439, 2012.

[10]  S. Motsch and E. Tadmor, “A New Model for Self-organized Dynamics and Its Flocking Behavior,” J. Stat. Phys., vol. 144, no. 5, pp. 923–947, 2011.

[11]  J. Shen, “Cucker-smale flocking under hierarchical leadership,” SIAM J. Appl. Math., vol. 68, no. 3, pp. 694–719, 2007.

[12]  Z. LI and XIAOPING XUE, “CUCKER–SMALE FLOCKING UNDER ROOTED LEADERSHIP WITH FIXED AND SWITCHING TOPOLOGIES,” SIAM J. Appl. Math., vol. 70, no. 8, pp. 3156–3174, 2010.

[13]  Jiu-Gang Dong, “Flocking under hierarchical leadership with a free-will leader,” Int. J. Robust Nonlinear Control, vol. 18, no. October 2014, pp. 557–569, 2012.

[14]  R. Sepulchre, D. A. Paley, and N. E. Leonard, “Stabilization of planar collective motion: All-to-all communication,” IEEE Trans. Automat. Contr., vol. 52, no. 5, pp. 811–824, 2007.

[15]  A. Papachristodoulou and A. Jadbabaie, “Synchronization in oscillator networks: Switching topologies and non-homogeneous delays,” Proc. 44th IEEE Conf. Decis. Control. Eur. Control Conf. CDC-ECC ’05, vol. 2005, pp. 5692–5697, 2005.

[16]  A. Jadbabaie, N. Motee, and M. Barahona, “On the stability of the Kuramoto model of coupled nonlinear oscillators,” Proc. Am. Control Conf., vol. 5, pp. 4296–4301, 2004.

[17]  W. Gao, Z. P. Jiang, F. L. Lewis, and Y. Wang, “Leader-to-Formation Stability of Multiagent Systems: An Adaptive Optimal Control Approach,” IEEE Trans. Automat. Contr., vol. 63, no. 10, pp. 3581–3587, 2018.

[18]  Y. Wang and Y. Song, “Leader-following control of high-order multi-agent systems under directed graphs: Pre-specified finite time approach,” Automatica, vol. 87, pp. 113–120, 2018.

[19]  Y. Zheng, Y. Zhu, and L. Wang, “Consensus of heterogeneous multi-agent systems,” IET Control Theory Appl., vol. 5, no. 16, pp. 1881–1888, 2011.

[20]  J. M. Kim, J. B. Park, and Y. H. Choi, “Leaderless and leader-following consensus for heterogeneous multi-agent systems with random link failures,” IET Control Theory Appl., vol. 8, no. 1, pp. 51–60, 2014.

[21]  D. Yang, W. Ren, X. Liu, and W. Chen, “Decentralized event-triggered consensus for linear multi-agent systems under general directed graphs,” Automatica, vol. 69, pp. 242–249, 2016.

[22]  C. Nowzari, E. Garcia, and J. Cortés, “Event-triggered communication and control of networked systems for multi-agent consensus,” Automatica, vol. 105, pp. 1–27, 2019.

[23]  Frans A. Oliehoek & Christopher Amato, A Concise Introduction to Decentralized POMDPs. 2015.

[24]  J. Hu and M. P. Wellman, “Nash Q-learning for general-sum stochastic games,” J. Mach. Learn. Res., vol. 4, no. 6, pp. 1039–1069, 2004.

[25]  K. Zhang, Z. Yang, H. Liu, T. Zhang, and T. Başar, “Fully Decentralized Multi-Agent Reinforcement Learning with Networked Agents,” pp. 1–45, 2018.

 



---

[1] http://www.red3d.com/cwr/boids/
